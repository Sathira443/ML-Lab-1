# -*- coding: utf-8 -*-
"""Lab1_label4.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1vRrsiQCAkvg5aZlEcdBV985MdVsqYxMY

Load training, testing data and import libraries
"""

import pandas as pd
import numpy as np

from imblearn.over_sampling import RandomOverSampler
from sklearn.preprocessing import StandardScaler
from sklearn.neighbors import KNeighborsClassifier
from sklearn.decomposition import PCA

train_data = pd.read_csv("/content/drive/MyDrive/Colab Notebooks/train.csv")
test_data = pd.read_csv("/content/drive/MyDrive/Colab Notebooks/valid.csv")

test_features = test_data.drop(['label_2', 'label_3', 'label_1'], axis=1)
test_labels = test_features.pop('label_4')

train_features = train_data.drop(['label_2', 'label_3', 'label_1'], axis=1)
train_labels = train_features.pop('label_4')

# Handle class imbalance using oversampling
oversampler = RandomOverSampler(sampling_strategy='auto')
train_features, train_labels = oversampler.fit_resample(train_features, train_labels)

# Scale the data
scaler = StandardScaler()
scaler.fit(train_features)
train_features_scaled = scaler.transform(train_features)
test_features_scaled = scaler.transform(test_features)

# Train k-nearest neighbors classifier before PCA
k_value = 5
knn_model_before = KNeighborsClassifier(n_neighbors=k_value)
knn_model_before.fit(train_features_scaled, train_labels)
predicted_labels_before = knn_model_before.predict(test_features_scaled)

# Perform PCA
pca = PCA(0.95)  # Preserve 95% of variance
pca.fit(train_features_scaled)
train_features_pca = pca.transform(train_features_scaled)
test_features_pca = pca.transform(test_features_scaled)

# Train k-nearest neighbors classifier after PCA
knn_model_after = KNeighborsClassifier(n_neighbors=k_value)
knn_model_after.fit(train_features_pca, train_labels)
predicted_labels_after = knn_model_after.predict(test_features_pca)

# Create a DataFrame for transformed features
pca_feature_names = [f"new_feature_{i}" for i in range(1, test_features_pca.shape[1] + 1)]
pca_df = pd.DataFrame(test_features_pca, columns=pca_feature_names)

# Prepare data for CSV export
result_data = {
    'Predicted labels before feature engineering': predicted_labels_before,
    'Predicted labels after feature engineering': predicted_labels_after,
    'No of new features': [test_features_pca.shape[1]] * len(test_features_pca),
}

# Create a DataFrame using the result_data dictionary
result_df = pd.DataFrame(result_data)

# Concatenate the PCA-transformed features DataFrame with the result DataFrame
final_df = pd.concat([result_df, pca_df], axis=1)

# Export DataFrame to CSV
csv_file_path = '../../Downloads/190359P_label_4.csv'
final_df.to_csv(csv_file_path, index=False)